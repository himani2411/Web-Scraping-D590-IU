{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9xjNc7N25l_"
      },
      "source": [
        "# Web Scraping assignment 6\n",
        "by Himani Anil Deshpande"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc3wrHlU23rj",
        "outputId": "dedb5133-43dd-4a4e-86b2-0aa61a1580dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scrapy\n",
            "  Downloading Scrapy-2.6.1-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting zope.interface>=4.1.3\n",
            "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
            "\u001b[K     |████████████████████████████████| 251 kB 38.2 MB/s \n",
            "\u001b[?25hCollecting itemadapter>=0.1.0\n",
            "  Downloading itemadapter-0.5.0-py3-none-any.whl (10 kB)\n",
            "Collecting PyDispatcher>=2.0.5\n",
            "  Downloading PyDispatcher-2.0.5.zip (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting parsel>=1.5.0\n",
            "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting w3lib>=1.17.0\n",
            "  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting Twisted>=17.9.0\n",
            "  Downloading Twisted-22.2.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.2.6)\n",
            "Collecting itemloaders>=1.0.1\n",
            "  Downloading itemloaders-1.0.4-py3-none-any.whl (11 kB)\n",
            "Collecting protego>=0.1.15\n",
            "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-3.2.0-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.0\n",
            "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 41.5 MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.1\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting queuelib>=1.4.2\n",
            "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pyOpenSSL>=16.2.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting service-identity>=16.0.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from scrapy) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.21)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: six>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from parsel>=1.5.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (21.4.0)\n",
            "Collecting incremental>=21.3.0\n",
            "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.9.0->scrapy) (3.10.0.2)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (2.10)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (3.6.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tldextract->scrapy) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->tldextract->scrapy) (1.24.3)\n",
            "Building wheels for collected packages: PyDispatcher\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-py3-none-any.whl size=11516 sha256=7412446452516708ba3502d2d7aba4f8e739df3ba5400f64a34f9f42223384a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/18/21/3c6a732eaa69a339198e08bb63b7da2c45933a3428b29ec454\n",
            "Successfully built PyDispatcher\n",
            "Installing collected packages: w3lib, cssselect, zope.interface, requests-file, parsel, jmespath, itemadapter, incremental, hyperlink, cryptography, constantly, Automat, Twisted, tldextract, service-identity, queuelib, pyOpenSSL, PyDispatcher, protego, itemloaders, scrapy\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-22.2.0 constantly-15.1.0 cryptography-36.0.2 cssselect-1.1.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.5.0 itemloaders-1.0.4 jmespath-1.0.0 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.0.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.6.1 service-identity-21.1.0 tldextract-3.2.0 w3lib-1.22.0 zope.interface-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scrapy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0iI1gXu0gJs"
      },
      "source": [
        "# Question 1\n",
        "\n",
        "From the given Stackoverflow page, extract all the questions listed on the page.\n",
        "\n",
        "url = https://stackoverflow.com/questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4AjJBrY4YtL"
      },
      "outputs": [],
      "source": [
        "import scrapy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o92QXMl233hE",
        "outputId": "278658d6-e343-48ad-b64a-f8c599c14bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-09 23:55:56 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-04-09 23:55:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.7.13 (default, Mar 16 2022, 17:37:17) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-04-09 23:55:56 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
            " 'LOGSTATS_INTERVAL': 0}\n",
            "2022-04-09 23:55:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-04-09 23:55:56 [scrapy.extensions.telnet] INFO: Telnet Password: fb5bd6f907299d85\n",
            "2022-04-09 23:55:56 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage']\n",
            "2022-04-09 23:55:57 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-04-09 23:55:57 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-04-09 23:55:57 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-04-09 23:55:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-04-09 23:55:57 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Attempting to acquire lock 140543228714320 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Lock 140543228714320 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Attempting to acquire lock 140543228714000 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Lock 140543228714000 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Attempting to release lock 140543228714000 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Lock 140543228714000 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Attempting to release lock 140543228714320 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [filelock] DEBUG: Lock 140543228714320 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:55:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/questions> (referer: None)\n",
            "[s] Available Scrapy objects:\n",
            "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
            "[s]   crawler    <scrapy.crawler.Crawler object at 0x7fd2c78eef50>\n",
            "[s]   item       {}\n",
            "[s]   request    <GET https://stackoverflow.com/questions>\n",
            "[s]   response   <200 https://stackoverflow.com/questions>\n",
            "[s]   settings   <scrapy.settings.Settings object at 0x7fd2c77ec590>\n",
            "[s]   spider     <DefaultSpider 'default' at 0x7fd2c70255d0>\n",
            "[s] Useful shortcuts:\n",
            "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
            "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
            "[s]   shelp()           Shell help (print this help)\n",
            "[s]   view(response)    View response in a browser\n",
            "\u001b[79Ct\u001b[0m\n",
            "\u001b[0;38;5;28m   ...: \u001b[0mract\u001b[0m()\u001b[14D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[0m\u001b[?7h\u001b[0;38;5;88mOut[\u001b[0;38;5;9;1m1\u001b[0;38;5;88m]: \u001b[0m\n",
            "['Best way to run VM via virt-install/virt-manager on Apple Silicone',\n",
            " 'How do you use/deploy docker?',\n",
            " 'JavaScript Regexp construction: Invalid regular expression: Nothing to repeat',\n",
            " \"Flutter: Execution failed for task ':location:compileDebugKotlin' while trying to build app\",\n",
            " 'Pls I need explanation of this code snippet written in Haml',\n",
            " 'Loading sentence transformer model in streamlit taking FOREVER',\n",
            " 'Simple way to intercept requests on a single application?',\n",
            " 'How to stop Python from truncating print statements?',\n",
            " 'Converting a python code that uses local directories to an AWS Lambda function that reads a pdf file from a s3 bucket',\n",
            " 'How to reduce the memory usage when reading infomation from a big xml file in C++',\n",
            " 'Type hinting on __aenter__ with generic inheritance is broken in PyCharm?',\n",
            " 'Elixir iex terminal prints ... instead of values',\n",
            " \"why isn't <navBar/> rendering? (react.js)\",\n",
            " 'Combine data with same ID',\n",
            " \"Incorrect syntax near the keyword 'if' SQL Command\",\n",
            " 'Understanding the sales fee for NFT erc721 secondary transaction',\n",
            " 'why is there a white space at the beggining of the body/html document (on top of the navigation bar)?',\n",
            " 'LeafletJS - Displaying HTML/DIV on selection of layer',\n",
            " 'Projectile Aim Prediction with Target Acceleration and Bullet Deceleration Varying with Angle',\n",
            " 'C - Appending an int to a string',\n",
            " 'How to connect NameCheap domain to DDNS?',\n",
            " 'Unable to load/require file from Lua running from Atom in Windows',\n",
            " 'Trying to make a Discord bot play a sound when someone joins the VC',\n",
            " 'Question on integer linear programming constraint',\n",
            " 'Calling Workflows from Scheduler',\n",
            " 'Play Sound in JAVA SWING program',\n",
            " 'How to split large table into 4 quarter from the most current day mysql',\n",
            " 'Getting null in firstName and lastName?',\n",
            " 'How to place two 3d models in different div? Three.js',\n",
            " 'Convert PDF to HTML via PyMuPDF',\n",
            " 'Python Twitter Bot Main Files not running all functions',\n",
            " 'Why should i use copy constructor?',\n",
            " 'OSMNX –\\xa0How to add nodes along an edge every N meters?',\n",
            " 'IOT PROJECT FOR NODEMCU',\n",
            " \"Display user's name in all html files using php and xml\",\n",
            " 'Can no longer view Jetpack Compose Previews. Failed to instantiate one or more classes (ComposeViewAdapter)',\n",
            " 'how to order output of arrays when using union',\n",
            " 'How to use trained model to detect objects - Tensorflow & Keras',\n",
            " 'c# Overlay multiple images with different opacity',\n",
            " 'how to create a left join query for a many to many related table with LINQ',\n",
            " 'Python - Python Interpreter with Multiprocessing & Multithread - Theoretical Clarification',\n",
            " \"tensorflow-gpu doesn't use both cpu and gpu\",\n",
            " 'Investment value calculator [closed]',\n",
            " 'Can LibreOffice convert an \"odg\" file to a \"docx\" file?',\n",
            " 'React-native Expo SpeechOptions',\n",
            " 'Concatenate each object property values of javascript array , properties are list of strings in javascript',\n",
            " 'Removing values from column within groups based on conditions',\n",
            " 'pyqtgraph cutting off axis numbers at top and right',\n",
            " 'When a push or pop instruction is being executed then what is the byte size of the value that is being pushed or popped?',\n",
            " 'Draggable widget and appbar flutter']\n",
            "\n",
            "\u001b[?1l\u001b[6n\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;38;5;10;1m2\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h^C\n"
          ]
        }
      ],
      "source": [
        "!scrapy shell \"https://stackoverflow.com/questions\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# !response.xpath('//*[@class=\"s-post-summary--content\"]//h3/a/text()').extract()"
      ],
      "metadata": {
        "id": "hQ3UvRZZtFDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used response.xpath('//*[@class=\"s-post-summary--content\"]//h3/a/text()').extract() command for question1"
      ],
      "metadata": {
        "id": "49cFjxQRFR0_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orKjJ8K81QQL"
      },
      "source": [
        "# Question 2.\n",
        " Request the page in Question 1 (or use the same shell) and fetch the hyperlink of each question listed on the page."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy shell \"https://stackoverflow.com/questions\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw1MG-JSwhUg",
        "outputId": "8c16f381-6cee-4c70-cc08-ef69c917eeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-09 23:58:39 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-04-09 23:58:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.7.13 (default, Mar 16 2022, 17:37:17) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-04-09 23:58:39 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
            " 'LOGSTATS_INTERVAL': 0}\n",
            "2022-04-09 23:58:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-04-09 23:58:39 [scrapy.extensions.telnet] INFO: Telnet Password: bcc48672811b5bb9\n",
            "2022-04-09 23:58:39 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage']\n",
            "2022-04-09 23:58:39 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-04-09 23:58:39 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-04-09 23:58:39 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-04-09 23:58:39 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-04-09 23:58:39 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Attempting to acquire lock 140484197442960 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Lock 140484197442960 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Attempting to acquire lock 140484197444752 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Lock 140484197444752 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Attempting to release lock 140484197444752 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Lock 140484197444752 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Attempting to release lock 140484197442960 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [filelock] DEBUG: Lock 140484197442960 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-09 23:58:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/questions> (referer: None)\n",
            "[s] Available Scrapy objects:\n",
            "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
            "[s]   crawler    <scrapy.crawler.Crawler object at 0x7fc5090573d0>\n",
            "[s]   item       {}\n",
            "[s]   request    <GET https://stackoverflow.com/questions>\n",
            "[s]   response   <200 https://stackoverflow.com/questions>\n",
            "[s]   settings   <scrapy.settings.Settings object at 0x7fc508f52a50>\n",
            "[s]   spider     <DefaultSpider 'default' at 0x7fc508788690>\n",
            "[s] Useful shortcuts:\n",
            "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
            "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
            "[s]   shelp()           Shell help (print this help)\n",
            "[s]   view(response)    View response in a browser\n",
            "\u001b[79Cr\u001b[0m\n",
            "\u001b[0;38;5;28m   ...: \u001b[0mact\u001b[0m()\u001b[13D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[0m\u001b[?7h\u001b[0;38;5;88mOut[\u001b[0;38;5;9;1m1\u001b[0;38;5;88m]: \u001b[0m\n",
            "['/questions/71812785/how-to-determine-an-empty-arrays-variable',\n",
            " '/questions/71812783/how-can-i-make-a-timer-appear-in-the-screen-of-my-game',\n",
            " '/questions/71812782/divide-with-commas-colummns-with-variable-spacing-to-create-a-manipulable-df',\n",
            " '/questions/71812780/python-trying-to-save-file-into-docker-volume',\n",
            " '/questions/71812778/how-do-i-make-an-enemy-damage-me-instead-of-killing-me',\n",
            " '/questions/71812776/best-way-to-run-vm-via-virt-install-virt-manager-on-apple-silicone',\n",
            " '/questions/71812774/how-do-you-use-deploy-docker',\n",
            " '/questions/71812772/javascript-regexp-construction-invalid-regular-expression-nothing-to-repeat',\n",
            " '/questions/71812771/flutter-execution-failed-for-task-locationcompiledebugkotlin-while-trying-t',\n",
            " '/questions/71812770/pls-i-need-explanation-of-this-code-snippet-written-in-haml',\n",
            " '/questions/71812769/loading-sentence-transformer-model-in-streamlit-taking-forever',\n",
            " '/questions/71812768/simple-way-to-intercept-requests-on-a-single-application',\n",
            " '/questions/71812767/how-to-stop-python-from-truncating-print-statements',\n",
            " '/questions/71812766/converting-a-python-code-that-uses-local-directories-to-an-aws-lambda-function-t',\n",
            " '/questions/71812765/how-to-reduce-the-memory-usage-when-reading-infomation-from-a-big-xml-file-in-c',\n",
            " '/questions/71812764/type-hinting-on-aenter-with-generic-inheritance-is-broken-in-pycharm',\n",
            " '/questions/71812763/elixir-iex-terminal-prints-instead-of-values',\n",
            " '/questions/71812762/why-isnt-navbar-rendering-react-js',\n",
            " '/questions/71812760/combine-data-with-same-id',\n",
            " '/questions/71812754/incorrect-syntax-near-the-keyword-if-sql-command',\n",
            " '/questions/71812749/understanding-the-sales-fee-for-nft-erc721-secondary-transaction',\n",
            " '/questions/71812746/why-is-there-a-white-space-at-the-beggining-of-the-body-html-document-on-top-of',\n",
            " '/questions/71812744/leafletjs-displaying-html-div-on-selection-of-layer',\n",
            " '/questions/71812742/projectile-aim-prediction-with-target-acceleration-and-bullet-deceleration-varyi',\n",
            " '/questions/71812741/c-appending-an-int-to-a-string',\n",
            " '/questions/71812739/how-to-connect-namecheap-domain-to-ddns',\n",
            " '/questions/71812737/unable-to-load-require-file-from-lua-running-from-atom-in-windows',\n",
            " '/questions/71812735/trying-to-make-a-discord-bot-play-a-sound-when-someone-joins-the-vc',\n",
            " '/questions/71812731/question-on-integer-linear-programming-constraint',\n",
            " '/questions/71812727/calling-workflows-from-scheduler',\n",
            " '/questions/71812723/play-sound-in-java-swing-program',\n",
            " '/questions/71812722/how-to-split-large-table-into-4-quarter-from-the-most-current-day-mysql',\n",
            " '/questions/71812720/getting-null-in-firstname-and-lastname',\n",
            " '/questions/71812719/how-to-place-two-3d-models-in-different-div-three-js',\n",
            " '/questions/71812718/convert-pdf-to-html-via-pymupdf',\n",
            " '/questions/71812715/python-twitter-bot-main-files-not-running-all-functions',\n",
            " '/questions/71812714/why-should-i-use-copy-constructor',\n",
            " '/questions/71812713/osmnx-how-to-add-nodes-along-an-edge-every-n-meters',\n",
            " '/questions/71812712/iot-project-for-nodemcu',\n",
            " '/questions/71812711/display-users-name-in-all-html-files-using-php-and-xml',\n",
            " '/questions/71812710/can-no-longer-view-jetpack-compose-previews-failed-to-instantiate-one-or-more-c',\n",
            " '/questions/71812709/how-to-order-output-of-arrays-when-using-union',\n",
            " '/questions/71812708/how-to-use-trained-model-to-detect-objects-tensorflow-keras',\n",
            " '/questions/71812707/c-sharp-overlay-multiple-images-with-different-opacity',\n",
            " '/questions/71812703/how-to-create-a-left-join-query-for-a-many-to-many-related-table-with-linq',\n",
            " '/questions/71812702/python-python-interpreter-with-multiprocessing-multithread-theoretical-cla',\n",
            " '/questions/71812700/tensorflow-gpu-doesnt-use-both-cpu-and-gpu',\n",
            " '/questions/71812697/investment-value-calculator',\n",
            " '/questions/71812695/can-libreoffice-convert-an-odg-file-to-a-docx-file',\n",
            " '/questions/71812694/react-native-expo-speechoptions']\n",
            "\n",
            "\u001b[?1l\u001b[6n\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;38;5;10;1m2\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# response.xpath('//*[@class=\"s-post-summary--content\"]//h3/a/@href').extract()"
      ],
      "metadata": {
        "id": "Hgl5UDi5FK_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used response.xpath('//*[@class=\"s-post-summary--content\"]//h3/a/@href').extract() for question 2\n"
      ],
      "metadata": {
        "id": "MYcs-SObwyq2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuOQeTEu59IF"
      },
      "source": [
        "# Question 3\n",
        "This is question is similar to the previous questions\n",
        "\n",
        "Go to the given Stackoverflow (jobs) page and extract the titles/role of all the jobs listed on the page.\n",
        "\n",
        "url = https://stackoverflow.com/jobs/companies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy shell 'https://stackoverflow.com/jobs/companies'"
      ],
      "metadata": {
        "id": "7bnoreO2xnpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96cdf267-586f-420e-ea74-2a78a0c208bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-10 00:34:26 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-04-10 00:34:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.7.13 (default, Mar 16 2022, 17:37:17) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-04-10 00:34:26 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
            " 'LOGSTATS_INTERVAL': 0}\n",
            "2022-04-10 00:34:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-04-10 00:34:26 [scrapy.extensions.telnet] INFO: Telnet Password: ca8f1d1e972c278b\n",
            "2022-04-10 00:34:26 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage']\n",
            "2022-04-10 00:34:26 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-04-10 00:34:26 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-04-10 00:34:26 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-04-10 00:34:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-04-10 00:34:26 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Attempting to acquire lock 139727821186896 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Lock 139727821186896 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Attempting to acquire lock 139727821188752 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Lock 139727821188752 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Attempting to release lock 139727821188752 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Lock 139727821188752 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Attempting to release lock 139727821186896 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [filelock] DEBUG: Lock 139727821186896 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:34:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies> (referer: None)\n",
            "[s] Available Scrapy objects:\n",
            "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
            "[s]   crawler    <scrapy.crawler.Crawler object at 0x7f14ed7b80d0>\n",
            "[s]   item       {}\n",
            "[s]   request    <GET https://stackoverflow.com/jobs/companies>\n",
            "[s]   response   <200 https://stackoverflow.com/jobs/companies>\n",
            "[s]   settings   <scrapy.settings.Settings object at 0x7f14ed6bf8d0>\n",
            "[s]   spider     <DefaultSpider 'default' at 0x7f14eceec6d0>\n",
            "[s] Useful shortcuts:\n",
            "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
            "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
            "[s]   shelp()           Shell help (print this help)\n",
            "[s]   view(response)    View response in a browser\n",
            "\u001b[79Cv\u001b[0m\n",
            "\u001b[0;38;5;28m   ...: \u001b[0;38;5;130m[2]/text()'\u001b[0m)\u001b[0m.\u001b[0mextract\u001b[0m()\u001b[30D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[0m\u001b[?7h\u001b[0;38;5;88mOut[\u001b[0;38;5;9;1m1\u001b[0;38;5;88m]: \u001b[0m\n",
            "[' Fashion, Retail',\n",
            " ' Agile Software Development, Autonomous Driving, Computer Vision',\n",
            " ' Financial Services',\n",
            " ' Cloud-Based Solutions, Computer Software, Enterprise Software',\n",
            " ' Banking, Financial Technology, Software Development / Engineering',\n",
            " ' Education Technology, eLearning, Non-Profit',\n",
            " ' Cloud Computing, Information Technology, Software Development',\n",
            " ' Software Development / Engineering',\n",
            " ' E-Commerce, Information Technology, Retail',\n",
            " ' Agile Software Development, Automotive, Mobility']\n",
            "\n",
            "\u001b[?1l\u001b[6n\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;38;5;10;1m2\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "# response.xpath('//*[@class=\"company-list\"]/div/div[3]/div[2]/div[1]/div[2]/text()').extract()"
      ],
      "metadata": {
        "id": "mQwA5SPtyCAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used response.xpath('//*[@class=\"company-list\"]/div/div[3]/div[2]/div[1]/div[2]/text()').extract() command for question 3\n"
      ],
      "metadata": {
        "id": "9Ykubc4j5UOG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TD8i7mjg5zWU"
      },
      "source": [
        "# Question 4. \n",
        "Fetching the location of the companies\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scrapy shell 'https://stackoverflow.com/jobs/companies'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STiv1ke55YU-",
        "outputId": "56e828da-725c-4b0f-bd28-a9d423c9f253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-10 00:35:40 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-04-10 00:35:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.7.13 (default, Mar 16 2022, 17:37:17) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-04-10 00:35:40 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'DUPEFILTER_CLASS': 'scrapy.dupefilters.BaseDupeFilter',\n",
            " 'LOGSTATS_INTERVAL': 0}\n",
            "2022-04-10 00:35:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-04-10 00:35:40 [scrapy.extensions.telnet] INFO: Telnet Password: 688137d8e43e12ee\n",
            "2022-04-10 00:35:40 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage']\n",
            "2022-04-10 00:35:40 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-04-10 00:35:40 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-04-10 00:35:40 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-04-10 00:35:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-04-10 00:35:40 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Attempting to acquire lock 140494897796624 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Lock 140494897796624 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Attempting to acquire lock 140494897798160 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Lock 140494897798160 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Attempting to release lock 140494897798160 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Lock 140494897798160 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Attempting to release lock 140494897796624 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [filelock] DEBUG: Lock 140494897796624 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 00:35:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies> (referer: None)\n",
            "[s] Available Scrapy objects:\n",
            "[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)\n",
            "[s]   crawler    <scrapy.crawler.Crawler object at 0x7fc786cfc390>\n",
            "[s]   item       {}\n",
            "[s]   request    <GET https://stackoverflow.com/jobs/companies>\n",
            "[s]   response   <200 https://stackoverflow.com/jobs/companies>\n",
            "[s]   settings   <scrapy.settings.Settings object at 0x7fc786bf7310>\n",
            "[s]   spider     <DefaultSpider 'default' at 0x7fc78642e610>\n",
            "[s] Useful shortcuts:\n",
            "[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)\n",
            "[s]   fetch(req)                  Fetch a scrapy.Request and update local objects \n",
            "[s]   shelp()           Shell help (print this help)\n",
            "[s]   view(response)    View response in a browser\n",
            "\u001b[79C[\u001b[0m\n",
            "\u001b[0;38;5;28m   ...: \u001b[0;38;5;130m1]/text()'\u001b[0m)\u001b[0m.\u001b[0mextract\u001b[0m()\u001b[29D\u001b[0m\n",
            "\u001b[J\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?2004l\u001b[0m\u001b[?7h\u001b[0;38;5;88mOut[\u001b[0;38;5;9;1m1\u001b[0;38;5;88m]: \u001b[0m\n",
            "[' Düsseldorf',\n",
            " ' Nürnberg; Wolfsburg; Mönsheim',\n",
            " ' Den Haag',\n",
            " ' Bracknell; Hlavní město Praha; Chaoyang Qu',\n",
            " ' San Diego; Allen; Albuquerque',\n",
            " ' San Francisco',\n",
            " ' Gent; Kortrijk; Charleroi',\n",
            " ' Houston; Cramlington; Groby',\n",
            " ' Düsseldorf; Stuttgart',\n",
            " ' München']\n",
            "\n",
            "\u001b[?1l\u001b[6n\u001b[?2004h\u001b[?25l\u001b[0m\u001b[?7l\u001b[0m\u001b[J\u001b[0;38;5;28mIn [\u001b[0;38;5;10;1m2\u001b[0;38;5;28m]: \u001b[8D\u001b[8C\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h\u001b[?25l\u001b[?7l\u001b[?7h\u001b[0m\u001b[?12l\u001b[?25h^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  response.xpath('//*[@class=\"company-list\"]/div/div[3]/div[2]/div[1]/div[1]/text()').extract()"
      ],
      "metadata": {
        "id": "9NdXI1Qk5gYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used ! response.xpath('//*[@class=\"company-list\"]/div/div[3]/div[2]/div[1]/div[1]/text()').extract() command for question 4"
      ],
      "metadata": {
        "id": "83oOWa685hQn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxlI0_PPJNQO"
      },
      "source": [
        "# Question 5.\n",
        "\n",
        "Write a spider to fetch details of the jobs listed on Stackoverflow jobs page. The details to be fetched are: Job title, Company, Location of the job. All the results must be written to a CSV file name jobs.csv.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class JobItem(scrapy.Item):\n",
        "   \n",
        "    name = scrapy.Field()\n",
        "    company_type = scrapy.Field()\n",
        "    location = scrapy.Field()\n",
        "\n",
        "class XPathPythonDocumentationSpider(scrapy.Spider):\n",
        "    name = 'company_location_details'\n",
        "    start_urls = ['https://stackoverflow.com/jobs/companies']\n",
        "\n",
        "    def parse(self, response):\n",
        "      \n",
        "        for data in response.xpath('//*[@class=\"company-list\"]/div/div[3]/div[2]'):\n",
        "\n",
        "        \n",
        "          item = JobItem()\n",
        "          item['name']= data.xpath('./h2/a/text()').extract()\n",
        "          item['location']= data.xpath('./div[1]/div[1]/text()').extract()\n",
        "          item['company_type'] = data.xpath('./div[1]/div[2]/text()').extract()\n",
        "          \n",
        "          yield item\n"
      ],
      "metadata": {
        "id": "yawsOGKsBgGz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMsrzuY188GO",
        "outputId": "9d059c84-af59-42d0-c025-954910a5f9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-10 01:34:09 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-04-10 01:34:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.7.13 (default, Mar 16 2022, 17:37:17) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "2022-04-10 01:34:09 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2022-04-10 01:34:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-04-10 01:34:09 [scrapy.extensions.telnet] INFO: Telnet Password: 9ef11bba128735a5\n",
            "2022-04-10 01:34:09 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-04-10 01:34:09 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-04-10 01:34:09 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-04-10 01:34:09 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-04-10 01:34:09 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-04-10 01:34:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-04-10 01:34:09 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Attempting to acquire lock 140247234442576 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Lock 140247234442576 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Attempting to acquire lock 140247234443920 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Lock 140247234443920 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Attempting to release lock 140247234443920 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Lock 140247234443920 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Attempting to release lock 140247234442576 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [filelock] DEBUG: Lock 140247234442576 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies> (referer: None)\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Fashion, Retail'],\n",
            " 'location': [' Düsseldorf'],\n",
            " 'name': ['Peek & Cloppenburg KG Düsseldorf']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Agile Software Development, Autonomous Driving, Computer '\n",
            "                  'Vision'],\n",
            " 'location': [' Nürnberg; Wolfsburg; Mönsheim'],\n",
            " 'name': ['CARIAD ']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Financial Services'],\n",
            " 'location': [' Den Haag'],\n",
            " 'name': ['NN Group N.V.']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Cloud-Based Solutions, Computer Software, Enterprise '\n",
            "                  'Software'],\n",
            " 'location': [' Bracknell; Hlavní město Praha; Chaoyang Qu'],\n",
            " 'name': ['SUSE']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Banking, Financial Technology, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' San Diego; Allen; Albuquerque'],\n",
            " 'name': ['Jack Henry & Associates, Inc.®']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Education Technology, eLearning, Non-Profit'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['Wikimedia Foundation, Inc.']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Cloud Computing, Information Technology, Software '\n",
            "                  'Development'],\n",
            " 'location': [' Gent; Kortrijk; Charleroi'],\n",
            " 'name': ['Smals']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Software Development / Engineering'],\n",
            " 'location': [' Houston; Cramlington; Groby'],\n",
            " 'name': ['Baker Hughes']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' E-Commerce, Information Technology, Retail'],\n",
            " 'location': [' Düsseldorf; Stuttgart'],\n",
            " 'name': ['Breuninger GmbH & Co.']}\n",
            "2022-04-10 01:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Agile Software Development, Automotive, Mobility'],\n",
            " 'location': [' München'],\n",
            " 'name': ['FINN']}\n",
            "2022-04-10 01:34:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-04-10 01:34:10 [scrapy.extensions.feedexport] INFO: Stored csv feed (10 items) in: Question_5_first_page_data.csv\n",
            "2022-04-10 01:34:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 231,\n",
            " 'downloader/request_count': 1,\n",
            " 'downloader/request_method_count/GET': 1,\n",
            " 'downloader/response_bytes': 23168,\n",
            " 'downloader/response_count': 1,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'elapsed_time_seconds': 0.710465,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 4, 10, 1, 34, 10, 270450),\n",
            " 'httpcompression/response_bytes': 97552,\n",
            " 'httpcompression/response_count': 1,\n",
            " 'item_scraped_count': 10,\n",
            " 'log_count/DEBUG': 20,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 94601216,\n",
            " 'memusage/startup': 94601216,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2022, 4, 10, 1, 34, 9, 559985)}\n",
            "2022-04-10 01:34:10 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ],
      "source": [
        "!scrapy runspider question5.py -o Question_5_first_page_data.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gN5gCCcJGsh"
      },
      "source": [
        "# 6.\n",
        "\n",
        "Question 6\n",
        "Congrats on reaching this far! There is just one more question left. This question is an extension to the previous question.\n",
        "\n",
        "In Question 5, you have stored all the jobs listed on the first page. Now, add page following capability to the spider you have just written. There are approximately 108 pages of job listing on the website: https://stackoverflow.com/jobs?med=site-ui&ref=jobs-tab.\n",
        "\n",
        "Crawl all the pages and store all the jobs postings to a CSV file.\n",
        "\n",
        "Hint: Just follow the link referred by next button at the bottom of each page. (See Following section in Lecture 20)\n",
        "\n",
        "Tip: Write the URL following code before processing the job data in parse(). This makes the program run faster. There is no need to write a new parse method as the new page we request has the same structure as the current page. We can use the same parse() as call-back function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "UuyscI7OJBMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc61210d-4caf-43db-8550-93d9dc4f12a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://stackoverflow.com/jobs/companies', 'https://stackoverflow.com/jobs/companies?pg=2', 'https://stackoverflow.com/jobs/companies?pg=3', 'https://stackoverflow.com/jobs/companies?pg=4', 'https://stackoverflow.com/jobs/companies?pg=5', 'https://stackoverflow.com/jobs/companies?pg=6', 'https://stackoverflow.com/jobs/companies?pg=7', 'https://stackoverflow.com/jobs/companies?pg=8', 'https://stackoverflow.com/jobs/companies?pg=9', 'https://stackoverflow.com/jobs/companies?pg=10', 'https://stackoverflow.com/jobs/companies?pg=11', 'https://stackoverflow.com/jobs/companies?pg=12', 'https://stackoverflow.com/jobs/companies?pg=13', 'https://stackoverflow.com/jobs/companies?pg=14', 'https://stackoverflow.com/jobs/companies?pg=15', 'https://stackoverflow.com/jobs/companies?pg=16', 'https://stackoverflow.com/jobs/companies?pg=17', 'https://stackoverflow.com/jobs/companies?pg=18', 'https://stackoverflow.com/jobs/companies?pg=19', 'https://stackoverflow.com/jobs/companies?pg=20', 'https://stackoverflow.com/jobs/companies?pg=21', 'https://stackoverflow.com/jobs/companies?pg=22', 'https://stackoverflow.com/jobs/companies?pg=23', 'https://stackoverflow.com/jobs/companies?pg=24', 'https://stackoverflow.com/jobs/companies?pg=25', 'https://stackoverflow.com/jobs/companies?pg=26', 'https://stackoverflow.com/jobs/companies?pg=27', 'https://stackoverflow.com/jobs/companies?pg=28', 'https://stackoverflow.com/jobs/companies?pg=29', 'https://stackoverflow.com/jobs/companies?pg=30', 'https://stackoverflow.com/jobs/companies?pg=31', 'https://stackoverflow.com/jobs/companies?pg=32', 'https://stackoverflow.com/jobs/companies?pg=33', 'https://stackoverflow.com/jobs/companies?pg=34', 'https://stackoverflow.com/jobs/companies?pg=35', 'https://stackoverflow.com/jobs/companies?pg=36', 'https://stackoverflow.com/jobs/companies?pg=37', 'https://stackoverflow.com/jobs/companies?pg=38', 'https://stackoverflow.com/jobs/companies?pg=39', 'https://stackoverflow.com/jobs/companies?pg=40', 'https://stackoverflow.com/jobs/companies?pg=41', 'https://stackoverflow.com/jobs/companies?pg=42', 'https://stackoverflow.com/jobs/companies?pg=43', 'https://stackoverflow.com/jobs/companies?pg=44', 'https://stackoverflow.com/jobs/companies?pg=45', 'https://stackoverflow.com/jobs/companies?pg=46', 'https://stackoverflow.com/jobs/companies?pg=47']\n"
          ]
        }
      ],
      "source": [
        "import scrapy\n",
        "\n",
        "\n",
        "class JobItem(scrapy.Item):\n",
        "    \n",
        "    name = scrapy.Field()\n",
        "    company_type = scrapy.Field()\n",
        "    location = scrapy.Field()\n",
        "\n",
        "class urls():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def get_urls(self):\n",
        "    start_urls = ['https://stackoverflow.com/jobs/companies']\n",
        "    for i in range(2,48):\n",
        "      start_urls.append('https://stackoverflow.com/jobs/companies?pg='+ str(i))\n",
        "    return start_urls\n",
        "\n",
        "class XPathPythonDocumentationSpider(scrapy.Spider):\n",
        "    name = 'company_location_details'\n",
        "    start_urls = urls().get_urls()\n",
        "    print(start_urls)\n",
        "    def parse(self, response):\n",
        "        for data in response.xpath('//*[@class=\"company-list\"]/div/div[3]/div[2]'):\n",
        "\n",
        "        \n",
        "          item = JobItem()\n",
        "          item['name']= data.xpath('./h2/a/text()').extract()\n",
        "          item['location']= data.xpath('./div[1]/div[1]/text()').extract()\n",
        "          item['company_type'] = data.xpath('./div[1]/div[2]/text()').extract()\n",
        "          \n",
        "          yield item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9qKwVqtG6Gp",
        "outputId": "4799ec53-e9b7-40fa-f0bd-d07f23597327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-10 01:34:14 [scrapy.utils.log] INFO: Scrapy 2.6.1 started (bot: scrapybot)\n",
            "2022-04-10 01:34:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.6.0, libxml2 2.9.8, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.2.0, Python 3.7.13 (default, Mar 16 2022, 17:37:17) - [GCC 7.5.0], pyOpenSSL 22.0.0 (OpenSSL 1.1.1n  15 Mar 2022), cryptography 36.0.2, Platform Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n",
            "['https://stackoverflow.com/jobs/companies', 'https://stackoverflow.com/jobs/companies?pg=2', 'https://stackoverflow.com/jobs/companies?pg=3', 'https://stackoverflow.com/jobs/companies?pg=4', 'https://stackoverflow.com/jobs/companies?pg=5', 'https://stackoverflow.com/jobs/companies?pg=6', 'https://stackoverflow.com/jobs/companies?pg=7', 'https://stackoverflow.com/jobs/companies?pg=8', 'https://stackoverflow.com/jobs/companies?pg=9', 'https://stackoverflow.com/jobs/companies?pg=10', 'https://stackoverflow.com/jobs/companies?pg=11', 'https://stackoverflow.com/jobs/companies?pg=12', 'https://stackoverflow.com/jobs/companies?pg=13', 'https://stackoverflow.com/jobs/companies?pg=14', 'https://stackoverflow.com/jobs/companies?pg=15', 'https://stackoverflow.com/jobs/companies?pg=16', 'https://stackoverflow.com/jobs/companies?pg=17', 'https://stackoverflow.com/jobs/companies?pg=18', 'https://stackoverflow.com/jobs/companies?pg=19', 'https://stackoverflow.com/jobs/companies?pg=20', 'https://stackoverflow.com/jobs/companies?pg=21', 'https://stackoverflow.com/jobs/companies?pg=22', 'https://stackoverflow.com/jobs/companies?pg=23', 'https://stackoverflow.com/jobs/companies?pg=24', 'https://stackoverflow.com/jobs/companies?pg=25', 'https://stackoverflow.com/jobs/companies?pg=26', 'https://stackoverflow.com/jobs/companies?pg=27', 'https://stackoverflow.com/jobs/companies?pg=28', 'https://stackoverflow.com/jobs/companies?pg=29', 'https://stackoverflow.com/jobs/companies?pg=30', 'https://stackoverflow.com/jobs/companies?pg=31', 'https://stackoverflow.com/jobs/companies?pg=32', 'https://stackoverflow.com/jobs/companies?pg=33', 'https://stackoverflow.com/jobs/companies?pg=34', 'https://stackoverflow.com/jobs/companies?pg=35', 'https://stackoverflow.com/jobs/companies?pg=36', 'https://stackoverflow.com/jobs/companies?pg=37', 'https://stackoverflow.com/jobs/companies?pg=38', 'https://stackoverflow.com/jobs/companies?pg=39', 'https://stackoverflow.com/jobs/companies?pg=40', 'https://stackoverflow.com/jobs/companies?pg=41', 'https://stackoverflow.com/jobs/companies?pg=42', 'https://stackoverflow.com/jobs/companies?pg=43', 'https://stackoverflow.com/jobs/companies?pg=44', 'https://stackoverflow.com/jobs/companies?pg=45', 'https://stackoverflow.com/jobs/companies?pg=46', 'https://stackoverflow.com/jobs/companies?pg=47']\n",
            "2022-04-10 01:34:14 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'SPIDER_LOADER_WARN_ONLY': True}\n",
            "2022-04-10 01:34:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2022-04-10 01:34:14 [scrapy.extensions.telnet] INFO: Telnet Password: 51e3e42311f30f4d\n",
            "2022-04-10 01:34:14 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2022-04-10 01:34:14 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2022-04-10 01:34:14 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2022-04-10 01:34:14 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2022-04-10 01:34:14 [scrapy.core.engine] INFO: Spider opened\n",
            "2022-04-10 01:34:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2022-04-10 01:34:15 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Attempting to acquire lock 140538676814224 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Lock 140538676814224 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Attempting to acquire lock 140538676815440 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Lock 140538676815440 acquired on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Attempting to release lock 140538676815440 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Lock 140538676815440 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/urls/62bf135d1c2f3d4db4228b9ecaf507a2.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Attempting to release lock 140538676814224 on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [filelock] DEBUG: Lock 140538676814224 released on /root/.cache/python-tldextract/3.7.13.final__usr__7d8fdf__tldextract-3.2.0/publicsuffix.org-tlds/de84b5ca2167d4c83e38fb162f2e8738.tldextract.json.lock\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=7> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=3> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=5> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=6> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=4> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=8> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=2> (referer: None)\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Fashion, Retail'],\n",
            " 'location': [' Düsseldorf'],\n",
            " 'name': ['Peek & Cloppenburg KG Düsseldorf']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Agile Software Development, Autonomous Driving, Computer '\n",
            "                  'Vision'],\n",
            " 'location': [' Nürnberg; Wolfsburg; Mönsheim'],\n",
            " 'name': ['CARIAD ']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Financial Services'],\n",
            " 'location': [' Den Haag'],\n",
            " 'name': ['NN Group N.V.']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Cloud-Based Solutions, Computer Software, Enterprise '\n",
            "                  'Software'],\n",
            " 'location': [' Bracknell; Hlavní město Praha; Chaoyang Qu'],\n",
            " 'name': ['SUSE']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Banking, Financial Technology, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' San Diego; Allen; Albuquerque'],\n",
            " 'name': ['Jack Henry & Associates, Inc.®']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Education Technology, eLearning, Non-Profit'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['Wikimedia Foundation, Inc.']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Cloud Computing, Information Technology, Software '\n",
            "                  'Development'],\n",
            " 'location': [' Gent; Kortrijk; Charleroi'],\n",
            " 'name': ['Smals']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Software Development / Engineering'],\n",
            " 'location': [' Houston; Cramlington; Groby'],\n",
            " 'name': ['Baker Hughes']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' E-Commerce, Information Technology, Retail'],\n",
            " 'location': [' Düsseldorf; Stuttgart'],\n",
            " 'name': ['Breuninger GmbH & Co.']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies>\n",
            "{'company_type': [' Agile Software Development, Automotive, Mobility'],\n",
            " 'location': [' München'],\n",
            " 'name': ['FINN']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Embedded, Medical Devices, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Stäfa; Warsaw; Kitchener'],\n",
            " 'name': ['Sonova AG ']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Accounting, Consulting, Taxes'],\n",
            " 'location': [' Frankfurt am Main; Düsseldorf; Hamburg'],\n",
            " 'name': ['Deloitte Deutschland']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Restaurant'],\n",
            " 'location': [' Chicago'],\n",
            " 'name': [\"McDonald's Corporation\"]}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Automotive, Insurance, Software Development'],\n",
            " 'location': [' Crewe; Waterloo; Manchester'],\n",
            " 'name': ['IMS']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Financial Services, Financial Technology, Liquidity '\n",
            "                  'provider'],\n",
            " 'location': [' Amsterdam; New York; Cluj-Napoca'],\n",
            " 'name': ['Flow Traders']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' E-Commerce, Enterprise Software, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Schöppingen'],\n",
            " 'name': ['shopware AG']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Behavioral Analytics, HR Services, SaaS'],\n",
            " 'location': [' London'],\n",
            " 'name': ['Applied']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Agile Softwareentwicklung, Förderbank'],\n",
            " 'location': [' Karlsruhe'],\n",
            " 'name': ['L-Bank']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Automotive, Software Development'],\n",
            " 'location': [' München'],\n",
            " 'name': ['Audi Business Innovation GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' eCommerce, Internet Marketing'],\n",
            " 'location': [' Amsterdam; San Francisco; London'],\n",
            " 'name': ['eBay']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Collaboration Tools, Enterprise Software'],\n",
            " 'location': [' Arlington; Montreal'],\n",
            " 'name': ['Higher Logic']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Financial Technology, Mobile Payments'],\n",
            " 'location': [' United States; Hong Kong; China'],\n",
            " 'name': ['Coda Payments']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Software Development'],\n",
            " 'location': [' Cologne'],\n",
            " 'name': ['Giant Swarm GmbH ']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Electronics, Software Development / Engineering, Web '\n",
            "                  'Development'],\n",
            " 'location': [' München; Stuttgart; Dubai'],\n",
            " 'name': ['Motius GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Firmware Development, Hardware Development, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Delft; Nijmegen; Best'],\n",
            " 'name': ['Topic Embedded Systems B.V.']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Enterprise, Enterprise Software, Software Development'],\n",
            " 'location': [' Ramillies; Auderghem; San Francisco'],\n",
            " 'name': ['Odoo']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=7>\n",
            "{'company_type': [' Automotive, Computer Graphics, Project Management'],\n",
            " 'location': [' Ingolstadt; München'],\n",
            " 'name': ['Paradox Cat GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' eLearning, Hospitality'],\n",
            " 'location': [' Amsterdam'],\n",
            " 'name': ['Lobster Ink Technologies']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' eCommerce'],\n",
            " 'location': [' Warszawa; Barcelona; Lille'],\n",
            " 'name': ['Trusted Shops GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Financial Services'],\n",
            " 'location': [' München; London'],\n",
            " 'name': ['Scalable Capital GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Agile Software Development, Cloud-Based Solutions, '\n",
            "                  'Computer Software'],\n",
            " 'location': [' Dublin 1'],\n",
            " 'name': ['Arista Networks, Inc']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Product Development, Software Development / Engineering'],\n",
            " 'location': [' Sydney; Porto Alegre; Gold Coast'],\n",
            " 'name': ['Pragmateam']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Geographic Information System, GIS, Software Development'],\n",
            " 'location': [' Zürich; Vienna; New Delhi'],\n",
            " 'name': ['Esri']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Education, eLearning, Online-Coaching'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['WBS Gruppe']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' B2B, Construction, SaaS'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Cosuno']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Data & Analytics, Financial Services, Financial '\n",
            "                  'Technology'],\n",
            " 'location': [' Mumbai; Makati; Norman'],\n",
            " 'name': ['MSCI']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Financial Technology, Investment Banking, Platforms'],\n",
            " 'location': [' Berlin; Magdeburg'],\n",
            " 'name': ['Elinvar GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Electronics, Gambling, Gaming'],\n",
            " 'location': [' Gumpoldskirchen'],\n",
            " 'name': ['NOVOMATIC AG']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=3>\n",
            "{'company_type': [' Education, Education Technology, Video Streaming'],\n",
            " 'location': [' Karlsruhe; Thessaloniki; Troisdorf'],\n",
            " 'name': ['alfaview GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Mobile Application'],\n",
            " 'location': [' Pasching; Wien; Salzburg'],\n",
            " 'name': ['Runtastic']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Autonomous Driving, Energy Storage, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Gaimersheim; Wiesbaden; Berlin'],\n",
            " 'name': ['EDAG Group']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Advertising Technology, Data & Analytics, Media'],\n",
            " 'location': [' New York; Los Angeles; Toronto'],\n",
            " 'name': ['Night Market']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Computer Software, Information Technology, Software '\n",
            "                  'Development'],\n",
            " 'location': [' Umhlanga; Cape Town; Pretoria'],\n",
            " 'name': ['Derivco.']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Banking, Finance, Software Development'],\n",
            " 'location': [' Köln'],\n",
            " 'name': ['parcIT GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Entertainment, Gaming'],\n",
            " 'location': [' Msida; Douglas; Toronto'],\n",
            " 'name': [\"Bally's Interactive\"]}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Banking, Financial Services, Financial Technology'],\n",
            " 'location': [' Phoenix; Charlotte; Dallas'],\n",
            " 'name': ['MUFG']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' eCommerce, Fashion'],\n",
            " 'location': [' München; Philadelphia'],\n",
            " 'name': ['Stylight']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' AI Research, Machine Learning'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['kaliber.ai']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Beauty, Health & Fitness, Marketplace'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['StyleSeat']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Financial Technology, Marketplace'],\n",
            " 'location': [' Leawood'],\n",
            " 'name': ['C2FO']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Digital Marketing, Web Development, Web Technology'],\n",
            " 'location': [' Denver'],\n",
            " 'name': ['BlueModus']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' Milano; Warsaw; Verona'],\n",
            " 'name': ['Everli']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Computer Software, CRM, SaaS'],\n",
            " 'location': [' Spain; China; Argentina'],\n",
            " 'name': ['Avature']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' B2B, Content Marketing, Online Media'],\n",
            " 'location': [' Stuttgart'],\n",
            " 'name': ['RegioHelden GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Cybersecurity, Federal Agencies, Signals Analysis'],\n",
            " 'location': [' Augusta; San Antonio; Denver'],\n",
            " 'name': ['National Security Agency']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' Jamberoo; London; Wollongong'],\n",
            " 'name': ['FinoComp']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' eCommerce'],\n",
            " 'location': [' Assen; Amsterdam'],\n",
            " 'name': ['Catawiki']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Broadcast, IPTV, Software Development / Engineering'],\n",
            " 'location': [' Zürich; Berlin; Ann Arbor'],\n",
            " 'name': ['Zattoo']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Healthcare, Pharmaceuticals'],\n",
            " 'location': [' Tokyo; Lyon; Ridgefield'],\n",
            " 'name': ['Boehringer Ingelheim ']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' B2B, Electronics, Industrial Automation'],\n",
            " 'location': [' Sibiu; Rosenheim; Kressbronn am Bodensee'],\n",
            " 'name': ['ifm-Unternehmensgruppe']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Computer Software, Education Technology, Science'],\n",
            " 'location': [' Redwood City'],\n",
            " 'name': ['Chan Zuckerberg Initiative']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Software Development'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['X-Team']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Agile Software Development, Design, Fashion'],\n",
            " 'location': [' Stockholm; New York; Bengaluru'],\n",
            " 'name': ['H&M Hennes & Mauritz GBC AB']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Financial Services, Financial Technology, Information '\n",
            "                  'Technology'],\n",
            " 'location': [' Cherkasy; London; Tallinn'],\n",
            " 'name': ['Wise']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' E-Commerce, Information Technology'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Shopee Singapore Private Limited']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=5>\n",
            "{'company_type': [' Software Development / Engineering'],\n",
            " 'location': [' München; Berlin'],\n",
            " 'name': ['AVANTGARDE - \"Creating Fans\"']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Financial Services'],\n",
            " 'location': [' Dresher; Brainerd; Newton'],\n",
            " 'name': ['Ascensus']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Computer Software, Enterprise Software'],\n",
            " 'location': [' Zapopan; Santiago de Querétaro; Quận 10'],\n",
            " 'name': ['Wizeline']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Banking, Finance, Financial Technology'],\n",
            " 'location': [' Frankfurt am Main; Nürnberg'],\n",
            " 'name': ['ING Deutschland']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Software Development / Engineering, Video Streaming, Web '\n",
            "                  'Development'],\n",
            " 'location': [' San Francisco; Los Angeles; Irvine'],\n",
            " 'name': ['Chaturbate']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' E-Commerce, SaaS, Web Technology'],\n",
            " 'location': [' Hamburg'],\n",
            " 'name': ['ABOUT YOU SE & Co. KG']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Cloud-Based Solutions, HR Services, Software Development'],\n",
            " 'location': [' Madrid; Dublin; Amsterdam'],\n",
            " 'name': ['Personio']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Online Media, Publishing'],\n",
            " 'location': [' München; Köln'],\n",
            " 'name': ['social sweethearts® GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Computer Games, PC Games'],\n",
            " 'location': [' Horsham; Bulgaria'],\n",
            " 'name': ['Creative Assembly']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' Data & Analytics, E-Commerce, Food & Beverage'],\n",
            " 'location': [' Zaandam'],\n",
            " 'name': ['AH Technology – Albert Heijn']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=6>\n",
            "{'company_type': [' 3D Printing, Manufacturing, SaaS'],\n",
            " 'location': [' Paris; Amsterdam; Chicago'],\n",
            " 'name': ['Hubs']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=4>\n",
            "{'company_type': [' Cloud-Based Solutions, Information Technology, SaaS'],\n",
            " 'location': [' Graz; Zagreb; Leinfelden-Echterdingen'],\n",
            " 'name': ['atma.io ']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=8>\n",
            "{'company_type': [' Electronic equipment, Electronics, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Klaus; Salzburg; Berlin'],\n",
            " 'name': ['OMICRON electronics GmbH']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' Computer Software'],\n",
            " 'location': [' Elkridge; Linthicum Heights; Vienna'],\n",
            " 'name': ['Cipher Tech Solutions, Inc']}\n",
            "2022-04-10 01:34:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=2>\n",
            "{'company_type': [' eLearning, Software Development, Web Development'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Baeldung']}\n",
            "2022-04-10 01:34:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=11> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Cloud Services, Consulting, Information Technology'],\n",
            " 'location': [' Tampere; Helsinki'],\n",
            " 'name': ['Eficode Finland']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Construction, Information Technology, Software Development '\n",
            "                  '/ Engineering'],\n",
            " 'location': [' Heidelberg; Brno-jih'],\n",
            " 'name': ['HeidelbergCement AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Information Technology, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Regensburg'],\n",
            " 'name': ['knowis AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Agile Software Development, E-Commerce, Internet '\n",
            "                  'Marketing'],\n",
            " 'location': [' Karlsruhe; Berlin'],\n",
            " 'name': ['solute GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Automation, Computer Vision, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Hamburg'],\n",
            " 'name': ['EyeC GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Cybersecurity, Information Technology, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' London'],\n",
            " 'name': ['Mimecast']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Higher Education, Non-Profit'],\n",
            " 'location': [' Salt Lake City; Phoenix; Austin'],\n",
            " 'name': ['Western Governors University']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Automotive, Consulting, Software & Systems Engineering'],\n",
            " 'location': [' Erlangen; München; Hamburg'],\n",
            " 'name': ['Method Park ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' B2B, SaaS, Online Reputation Management'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['CA Customer Alliance GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=11>\n",
            "{'company_type': [' Education Technology, Healthcare, Medical'],\n",
            " 'location': [' Köln; Berlin; New York'],\n",
            " 'name': ['AMBOSS ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=10> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=14> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=13> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=12> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Digital Marketing'],\n",
            " 'location': [' الرياض; Riyadh'],\n",
            " 'name': ['Haraj.com']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Aerospace, Internet Infrastructure'],\n",
            " 'location': [' Hawthorne; Redmond; Brownsville'],\n",
            " 'name': ['SpaceX']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' Karlsruhe'],\n",
            " 'name': ['Disy Informationssysteme GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Artificial Intelligence, Digital Marketing, Machine '\n",
            "                  'Learning'],\n",
            " 'location': [' Amsterdam'],\n",
            " 'name': ['Relay42']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Mobile, Product Development, Web Development'],\n",
            " 'location': [' Köln; Berlin; Malmö'],\n",
            " 'name': ['eyeo GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Life Sciences, SaaS, Software Development'],\n",
            " 'location': [' Blue Bell'],\n",
            " 'name': ['Pinnacle 21']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Information Technology, Software Development / '\n",
            "                  'Engineering, Web Development'],\n",
            " 'location': [' Weiningen'],\n",
            " 'name': ['M&F Engineering AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Banking'],\n",
            " 'location': [' Solna; Stockholm; Karlstad'],\n",
            " 'name': ['SBAB Bank']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' Casino, Gambling'],\n",
            " 'location': [' Wien; Raaba; Birkirkara'],\n",
            " 'name': ['Greentube GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=10>\n",
            "{'company_type': [' E-Commerce, Information Technology, Logistics and Supply '\n",
            "                  'Chain'],\n",
            " 'location': [' Düsseldorf; Amsterdam'],\n",
            " 'name': ['Picnic']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Online Travel, Travel & Tourism, Travel Planning'],\n",
            " 'location': [' München'],\n",
            " 'name': ['roadsurfer GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Insurance'],\n",
            " 'location': [' Köln'],\n",
            " 'name': ['DEVK Versicherungen']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Charging, Solar'],\n",
            " 'location': [' München'],\n",
            " 'name': ['VISPIRON CHARGE-V GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Computer Software, Enterprise Software, Real Estate'],\n",
            " 'location': [' Cambridge; Dallas'],\n",
            " 'name': ['Lone Wolf Technologies']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' 3D Printing, Dental, Retail'],\n",
            " 'location': [' Nashville; Cartago'],\n",
            " 'name': ['SmileDirectClub']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' eCommerce, Headless Technology, Mobile Development'],\n",
            " 'location': [' Pittsburgh'],\n",
            " 'name': ['Branding Brand']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Capital Markets, Financial Technology, High Frequency '\n",
            "                  'Trading'],\n",
            " 'location': [' Amsterdam; Chicago; The Rocks'],\n",
            " 'name': ['IMC Trading']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Pharmacy, Software Development / Engineering'],\n",
            " 'location': [' Frankfurt am Main'],\n",
            " 'name': ['LORENZ Life Sciences Group']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Computer Software, IT Consulting, Software Development'],\n",
            " 'location': [' Göteborg; Stockholm'],\n",
            " 'name': ['Callista Enterprise AB']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Data & Analytics, Machine Learning, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Karlsruhe; Berlin'],\n",
            " 'name': ['QuantCo ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Agile Software Development, Software Development, Web '\n",
            "                  'Development'],\n",
            " 'location': [' Köln'],\n",
            " 'name': ['Ambient ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Machine Learning, Medical Devices, Virtual Reality'],\n",
            " 'location': [' Oberkochen; Jena; Roßdorf'],\n",
            " 'name': ['ZEISS Group']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Android, Financial Technology, iOS'],\n",
            " 'location': [' Haarlem'],\n",
            " 'name': ['BOTS by RevenYOU']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Cybersecurity, DevOps, Internet Infrastructure'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['Copado Strategic Services']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Hardware Development, Mobile Development, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Annecy; Bozen; Sunne'],\n",
            " 'name': ['Axess AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Industrial Automation, Internet of Things'],\n",
            " 'location': [' Berlin; München; Chicago'],\n",
            " 'name': ['Relayr']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Health & Fitness'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['iFit']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=14>\n",
            "{'company_type': [' Energy & Environment, Energy & Utilities, Green Energy'],\n",
            " 'location': [' London; Melbourne; Munich'],\n",
            " 'name': ['Octopus Energy']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Information Technology, IT Security, Network Security'],\n",
            " 'location': [' Austin'],\n",
            " 'name': ['Sailpoint Technologies, Inc.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Cloud Computing, CRM-System for real estate industry, '\n",
            "                  'Software Development'],\n",
            " 'location': [' Aachen'],\n",
            " 'name': ['onOffice GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Consumer Electronics'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Lautsprecher Teufel GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Cybersecurity, Healthcare'],\n",
            " 'location': [' United States'],\n",
            " 'name': ['Tausight']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Software Consulting, Software Development, Web '\n",
            "                  'Development'],\n",
            " 'location': [' Dresden; Solothurn; Berlin'],\n",
            " 'name': ['queo GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Information Technology, Mobile Development, Software '\n",
            "                  'Development'],\n",
            " 'location': [' Berlin; Köln; Freiburg im Breisgau'],\n",
            " 'name': ['tarent solutions GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' HR tech, Information Technology'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Zenjob']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Casino, Gaming'],\n",
            " 'location': [' Stockholm; Västerås; Växjö'],\n",
            " 'name': ['LeoVegas Mobile Gaming Group']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Agile Software Development, IT Consulting, Software '\n",
            "                  'Consulting'],\n",
            " 'location': [' Weinheim; Berlin'],\n",
            " 'name': ['objective partner AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=13>\n",
            "{'company_type': [' Agile Software Development, Simulation Software, Software '\n",
            "                  'Development'],\n",
            " 'location': [' Heidelberg; Singapore; Chaoyang Qu'],\n",
            " 'name': ['Volume Graphics GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Automation, Business Process Optimization, Information '\n",
            "                  'Technology'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['camunda ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=12>\n",
            "{'company_type': [' Industrial Automation, Information Technology, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Cluj-Napoca; Timișoara; Târgu Mureș'],\n",
            " 'name': ['Accenture Romania']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=18> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=19> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=17> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=20> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Corporate Training, Online-Coaching, SaaS'],\n",
            " 'location': [' Austin'],\n",
            " 'name': ['Betterup, Inc.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Information Technology, Web Hosting'],\n",
            " 'location': [' Deventer; Rotterdam; Eindhoven'],\n",
            " 'name': ['team.blue NL B.V.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Cloud Computing, Education Technology, SaaS'],\n",
            " 'location': [' Edinburgh; Beirut; Bozeman'],\n",
            " 'name': ['Administrate']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Telematics'],\n",
            " 'location': [' München'],\n",
            " 'name': ['CARSYNC GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Databases, Enterprise Software, Information Technology'],\n",
            " 'location': [' Arlington'],\n",
            " 'name': ['Stardog Union']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Computer Software, Financial Services, Software '\n",
            "                  'Development'],\n",
            " 'location': [' Princeton'],\n",
            " 'name': ['Edgestream Partners, L.P.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Energy & Commodities, Energy & Environment, Energy & '\n",
            "                  'Utilities'],\n",
            " 'location': [' Köln'],\n",
            " 'name': ['RheinEnergie AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' IT Consulting, Software Development'],\n",
            " 'location': [' Luzern; Zug; Zürich'],\n",
            " 'name': ['bbv Software Services AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Logistics & Distribution, Logistics and Supply Chain, '\n",
            "                  'SaaS'],\n",
            " 'location': [' Rotterdam'],\n",
            " 'name': ['Shypple']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=18>\n",
            "{'company_type': [' Energy Storage, Green Energy'],\n",
            " 'location': [' Bristol; London; Edinburgh'],\n",
            " 'name': ['OVO Group']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Agile Software Development, Data Science, DevOps'],\n",
            " 'location': [' Porto'],\n",
            " 'name': ['Zühlke Engineering Portugal']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Adserver, Media, Web Hosting'],\n",
            " 'location': [' Düsseldorf; Berlin; Hamburg'],\n",
            " 'name': ['virtual minds AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Big Data, Data Management Platform, Programmatic '\n",
            "                  'Advertising'],\n",
            " 'location': [' Berlin; Hamburg'],\n",
            " 'name': ['The ADEX GmbH ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Financial Services, Insurance'],\n",
            " 'location': [' Toronto; Seattle; Fort Lauderdale'],\n",
            " 'name': ['Assurance']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Digital Media, Online Media, Video Streaming'],\n",
            " 'location': [' Luxembourg'],\n",
            " 'name': ['Docler Holding']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Banking, Financial Services, Financial Technology'],\n",
            " 'location': [' New York; Vienna; São Paulo'],\n",
            " 'name': ['N26']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Cloud-Based Solutions, Integrated Marketing Solutions, '\n",
            "                  'SaaS'],\n",
            " 'location': [' McKinney'],\n",
            " 'name': ['FieldRoutes']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Pharmaceuticals'],\n",
            " 'location': [' Denmark'],\n",
            " 'name': ['Novo Nordisk A/S']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Consulting, Product Development, Technology Consulting'],\n",
            " 'location': [' New York'],\n",
            " 'name': ['PwC']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=19>\n",
            "{'company_type': [' Computer Software'],\n",
            " 'location': [' New York'],\n",
            " 'name': ['Postlight']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Automotive, Digital Advertising, Digital Media'],\n",
            " 'location': [' Toronto; Montréal'],\n",
            " 'name': ['AutoTrader']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' B2B, Content Marketing, Online Media'],\n",
            " 'location': [' Stuttgart; Köln; Hamburg'],\n",
            " 'name': ['Ströer Online Marketing']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Agile Software Development, CMS, Enterprise Software'],\n",
            " 'location': [' Münchenstein; Singapore; New York'],\n",
            " 'name': ['Magnolia International Ltd.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Agile Software Development, Consulting, Defence & '\n",
            "                  'Security'],\n",
            " 'location': [' Baltimore; Aberdeen Proving Ground; Fort Meade'],\n",
            " 'name': ['Captivation Software']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Real Estate'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Ziegert EverEstate GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' 3D Models, Configuration Management, Web Technology'],\n",
            " 'location': [' Sankt Wendel; Saarbrücken'],\n",
            " 'name': ['KiM GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' Chicago'],\n",
            " 'name': ['tastyworks']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' eCommerce, Information Technology, Online Travel'],\n",
            " 'location': [' Madrid; Barcelona; Milano'],\n",
            " 'name': ['eDreams ODIGEO']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Digital Health, Healthcare'],\n",
            " 'location': [' Rochester'],\n",
            " 'name': ['Mayo Clinic']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Automotive, Information Services, Information Technology'],\n",
            " 'location': [' Veghel'],\n",
            " 'name': ['BAS ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Higher Education, SaaS'],\n",
            " 'location': [' Overland Park'],\n",
            " 'name': ['Ad Astra']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Healthcare'],\n",
            " 'location': [' California; Orlando; Bend'],\n",
            " 'name': ['Abbott']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Cloud Services, Information Technology, Security Software'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Kyndryl']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Enterprise Software, Language Services, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Acrolinx']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Government, Information Technology, Public Services'],\n",
            " 'location': [' London'],\n",
            " 'name': ['Government Digital Service (GDS)']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Finance, Financial Technology'],\n",
            " 'location': [' Charlotte; United States'],\n",
            " 'name': ['Cardinal Financial Company, LP']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Financial Technology'],\n",
            " 'location': [' Lehi'],\n",
            " 'name': ['SimpleNexus LLC']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=17>\n",
            "{'company_type': [' Computer Software, DevOps, Mobile Application'],\n",
            " 'location': [' New York; Los Angeles; Bothell'],\n",
            " 'name': ['econify']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Lendico Deutschland GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=20>\n",
            "{'company_type': [' Computer Software, Financial Technology, Information '\n",
            "                  'Technology'],\n",
            " 'location': [' Lausanne'],\n",
            " 'name': ['Edgelab']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=21> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=24> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' IT Services'],\n",
            " 'location': [' Los Angeles'],\n",
            " 'name': ['Citrusbyte']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Agile Software Development, Cloud-Based Solutions, SaaS'],\n",
            " 'location': [' Köln'],\n",
            " 'name': ['Trusted Shops']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Consumer Electronics'],\n",
            " 'location': [' Cupertino; Austin; Haifa'],\n",
            " 'name': ['Apple']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Mobile Game'],\n",
            " 'location': [' København'],\n",
            " 'name': [' SYBO']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Data & Analytics, Financial Technology, News'],\n",
            " 'location': [' New York; Princeton; London'],\n",
            " 'name': ['Bloomberg LP']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' E-Commerce, Online Advertising, SaaS'],\n",
            " 'location': [' Lüneburg'],\n",
            " 'name': ['Adference GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Agile Software Development, Embedded, Enterprise Software'],\n",
            " 'location': [' Wien'],\n",
            " 'name': ['Zühlke Engineering Austria']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Computer Software, Hardware Engineering, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Beograd'],\n",
            " 'name': ['Zuhlke Engineering d.o.o.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Agile Software Development, Computer Software'],\n",
            " 'location': [' Sofia'],\n",
            " 'name': ['Zuhlke Engineering EOOD']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=21>\n",
            "{'company_type': [' Agile Software Development, Enterprise Software, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Eschborn; München; Stuttgart'],\n",
            " 'name': ['Zühlke Engineering GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=9> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=15> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' B2B, B2C, Financial Services'],\n",
            " 'location': [' Wiesbaden'],\n",
            " 'name': ['SOLIT Management GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Agile Software Development, Government'],\n",
            " 'location': [' Düsseldorf; Berlin'],\n",
            " 'name': ['publicplan']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Banking, Finance'],\n",
            " 'location': [' Wien'],\n",
            " 'name': ['bank99']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' E-Commerce'],\n",
            " 'location': [' Wien'],\n",
            " 'name': ['Post E-Commerce GmbH/shöpping']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Manufacturing'],\n",
            " 'location': [' Tucson; San Diego'],\n",
            " 'name': ['Rain Bird Corporation']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Consumer Electronics, E-Commerce, Re-Commerce'],\n",
            " 'location': [' Frankfurt (Oder); Berlin'],\n",
            " 'name': ['asgoodasnew electronics GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Automotive, Electronics, Information Technology'],\n",
            " 'location': [' Blomberg'],\n",
            " 'name': ['PHOENIX CONTACT GmbH & Co. KG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=16> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Computer Software'],\n",
            " 'location': [' Stenungsund'],\n",
            " 'name': ['Hogia']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' Financial Technology, Quantitative Market Making'],\n",
            " 'location': [' New York; London; Chicago'],\n",
            " 'name': ['Old Mission Capital, LLC']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=24>\n",
            "{'company_type': [' eCommerce, Information Technology, Logistics and Supply '\n",
            "                  'Chain'],\n",
            " 'location': [' Utrecht'],\n",
            " 'name': ['Cycleon']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Cybersecurity, Defence & Security, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Bremen; Düsseldorf'],\n",
            " 'name': ['Rheinmetall ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Data & Analytics'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Azendian Solutions Pte. Ltd.']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=22> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Design, Software Consulting, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Lightmatter']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Banking, Financial Services, Financial Technology'],\n",
            " 'location': [' 香港島; Hong Kong'],\n",
            " 'name': ['WeLab Bank Limited']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Mobile Development, Software Development, Web Development'],\n",
            " 'location': [' Wien; Hong Kong Island; Khwaeng Phra Khanong'],\n",
            " 'name': ['OOZOU']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Cloud Computing, Consumer Electronics, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Nizhny Novgorod; Moscow; Mumbai'],\n",
            " 'name': ['Intel Corporation']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Computer Software, Recruiting, Technology Staffing'],\n",
            " 'location': [' Seattle'],\n",
            " 'name': ['Karat.com']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['ByteDance']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Information Technology, Tourism, Travel & Tourism'],\n",
            " 'location': [' Poznań; Bottighofen; Munich'],\n",
            " 'name': ['HolidayCheck Group AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=9>\n",
            "{'company_type': [' Computer Vision, Image Guided Surgery, Medical Imaging'],\n",
            " 'location': [' München'],\n",
            " 'name': ['ImFusion GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Agile Software Development, Software Development / '\n",
            "                  'Engineering, Web Development'],\n",
            " 'location': [' Fort Walton Beach'],\n",
            " 'name': ['Beast Code']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' eCommerce, Web Design, Web Development'],\n",
            " 'location': [' Pescara; Latina'],\n",
            " 'name': ['Nebulab']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Adserver, Programmatic Advertising, Video Streaming'],\n",
            " 'location': [' München; Berlin; Düsseldorf'],\n",
            " 'name': ['ADITION technologies AG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Mobile Application, Mobile Game'],\n",
            " 'location': [' Bad Nauheim; Frankfurt am Main'],\n",
            " 'name': ['Lotum GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Cloud Computing, Industrial Automation, Internet of '\n",
            "                  'Things'],\n",
            " 'location': [' Berlin; Eschborn; Limburg an der Lahn'],\n",
            " 'name': ['German Edge Cloud GmbH & Co. KG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Big Data, DevOps, Software Development / Engineering'],\n",
            " 'location': [' Toronto'],\n",
            " 'name': ['AIR MILES']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Automotive, SaaS'],\n",
            " 'location': [' München'],\n",
            " 'name': ['VEACT GmbH']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Financial Technology'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['Finsera']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Inventory Management Software, Supply Chain Management '\n",
            "                  'Software, Warehouse Management Software (WMS)'],\n",
            " 'location': [' Westminster; Del Mar'],\n",
            " 'name': ['EVS llc']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=23> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=15>\n",
            "{'company_type': [' Web Design, Web Development'],\n",
            " 'location': [' Chichester; London'],\n",
            " 'name': ['D3R']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Financial Technology, Information Technology'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Jewel Paymentech Pte Ltd']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Cybersecurity, Information Technology'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Ensign InfoSecurity (Cybersecurity) Pte Ltd']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Agile Software Development, Consulting, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Haarlem; Amsterdam'],\n",
            " 'name': ['Sytac IT Consulting ']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Business Intelligence, Data & Analytics, Developer APIs'],\n",
            " 'location': [' Atlanta; London; Arlington'],\n",
            " 'name': ['MapLarge']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' 3D Models, Construction, Information Technology'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Hubble Pte Ltd']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Artificial Intelligence, Consulting, Cybersecurity'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Amaris.AI']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Software und Services'],\n",
            " 'location': [' Monheim am Rhein; Hamburg; Hannover'],\n",
            " 'name': ['EPLAN Software & Service GmbH & Co. KG']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Cloud Services, Software Development / Engineering, '\n",
            "                  'Technology Consulting'],\n",
            " 'location': [' Götzis'],\n",
            " 'name': ['Fusonic']}\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' eCommerce, Financial Technology, Insurance'],\n",
            " 'location': [' Hong Kong; Sydney; Hoofddorp'],\n",
            " 'name': ['iptiQ by Swiss Re']}\n",
            "2022-04-10 01:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=25> (referer: None)\n",
            "2022-04-10 01:34:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=16>\n",
            "{'company_type': [' Agile Software Development, E-Commerce'],\n",
            " 'location': [' München; Bremen; Hamburg'],\n",
            " 'name': ['hmmh multimediahaus AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Automotive, Transportation'],\n",
            " 'location': [' Dearborn; Palo Alto; Detroit'],\n",
            " 'name': ['Ford Motor Company']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Enterprise Software, SaaS, Virtual Events'],\n",
            " 'location': [' Sofia; Lausanne'],\n",
            " 'name': ['SpotMe']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Bioinformatics, Data Science, Pharmaceuticals'],\n",
            " 'location': [' Biberach an der Riß; Wien; Ingelheim am Rhein'],\n",
            " 'name': ['Choose Your Challenge - Data Careers at Boehringer Ingelheim']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Agile Software Development, Digital Marketing, IT '\n",
            "                  'Recruitment'],\n",
            " 'location': [' Paris; Brooklyn; Zapopan'],\n",
            " 'name': ['Pentalog']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Automation, Logistics and Supply Chain'],\n",
            " 'location': [' Moosburg an der Isar; Norderstedt; Pinto'],\n",
            " 'name': ['Jungheinrich AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Banking, Financial Services, Financial Technology'],\n",
            " 'location': [' London; Zürich; Navi Mumbai'],\n",
            " 'name': ['CREDIT SUISSE AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Medical Software'],\n",
            " 'location': [' Annapolis'],\n",
            " 'name': ['RXNT']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' San Antonio; Irvine; Los Angeles'],\n",
            " 'name': ['Capital Group']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Computer Software, Design'],\n",
            " 'location': [' Guadalajara'],\n",
            " 'name': ['Envato Mexico']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=22>\n",
            "{'company_type': [' Computer Software, Databases, DevOps'],\n",
            " 'location': [' Cambridge'],\n",
            " 'name': ['Redgate Software']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Digital Advertising, Digital Marketing, Digital Media'],\n",
            " 'location': [' Kuala Lumpur; Hanoi; Amsterdam'],\n",
            " 'name': ['Sam Media']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Ad Tech, Gaming'],\n",
            " 'location': [' Los Angeles'],\n",
            " 'name': ['Versus Systems']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Agile Software Development, Data Science, IT Security'],\n",
            " 'location': [' Solna; Malmö; Linköping'],\n",
            " 'name': ['Säkerhetspolisen']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Agile Software Development, Data & Analytics, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Salem'],\n",
            " 'name': ['INNOSYSTEC GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Digital Marketing, Information Technology, Internet '\n",
            "                  'Marketing'],\n",
            " 'location': [' Berlin; London; Paris'],\n",
            " 'name': ['aklamio ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Mobile Application, Software Development, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' London'],\n",
            " 'name': ['Citymapper']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Government, Machine Learning, Public Safety'],\n",
            " 'location': [' Overland Park'],\n",
            " 'name': ['Daupler, Inc.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' B2B, Chemicals'],\n",
            " 'location': [' Leverkusen; Krefeld; Brunsbüttel'],\n",
            " 'name': ['Covestro']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Cloud Computing, Datacenter, Network Security'],\n",
            " 'location': [' Bratislava; Roma; Sofia'],\n",
            " 'name': ['Hewlett Packard Enterprise']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=23>\n",
            "{'company_type': [' Business to Business, Computer Software, Social '\n",
            "                  'Networking'],\n",
            " 'location': [' San Francisco; Oregon City'],\n",
            " 'name': ['Almanac']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Agile Software Development, Consulting, eCommerce'],\n",
            " 'location': [' Karlsruhe; Lisboa; Berlin'],\n",
            " 'name': ['diconium group']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Big Data'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Cribl']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Events, Music, Travel & Tourism'],\n",
            " 'location': [' Los Angeles; London; Toronto'],\n",
            " 'name': ['Pollen']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Logistics & Distribution'],\n",
            " 'location': [' Wien'],\n",
            " 'name': ['Österreichische Post AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Computer Software'],\n",
            " 'location': [' Stenungsund'],\n",
            " 'name': ['Hogia']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Bonusprogramm, Product Development, Software Development'],\n",
            " 'location': [' München; Wien; Köln'],\n",
            " 'name': ['PAYBACK']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Computer Software, Human Resources, Software Development'],\n",
            " 'location': [' Atlanta; Weston; Toronto'],\n",
            " 'name': ['UKG (Ultimate Kronos Group)']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Mobile Game, Web Development'],\n",
            " 'location': [' Wien'],\n",
            " 'name': ['Platogo Interactive Entertainment GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Automotive, Digital platform, Machine Learning'],\n",
            " 'location': [' München'],\n",
            " 'name': ['4.screen GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=25>\n",
            "{'company_type': [' Consulting, Software Development'],\n",
            " 'location': [' Helsinki'],\n",
            " 'name': ['Rakettitiede']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=26> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=27> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Energy & Utilities, Information Technology'],\n",
            " 'location': [' Nottingham'],\n",
            " 'name': ['ENSEK']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' B2B Trade'],\n",
            " 'location': [' København; Aarhus; București'],\n",
            " 'name': ['Tradeshift']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Software Development / Engineering'],\n",
            " 'location': [' Hamburg'],\n",
            " 'name': ['Spaceteams GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Artificial Intelligence, Data & Analytics, Digital Media'],\n",
            " 'location': [' New York; London'],\n",
            " 'name': ['Signal AI']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Financial Services'],\n",
            " 'location': [' Boston; Chicago; San Francisco'],\n",
            " 'name': ['Capital One Financial Corporation']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Financial Services'],\n",
            " 'location': [' Buenos Aires; Herzliya; Bengaluru'],\n",
            " 'name': ['JPMorgan Chase & Co.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' Milwaukee; New York'],\n",
            " 'name': ['Northwestern Mutual']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Financial Services, Financial Technology, Regulatory '\n",
            "                  'Reporting'],\n",
            " 'location': [' Glasgow; Edinburgh'],\n",
            " 'name': ['AutoRek']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Business to Business, Security Software'],\n",
            " 'location': [' Fulton'],\n",
            " 'name': ['Enveil']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=26>\n",
            "{'company_type': [' Financial Services, Financial Technology, Payment Network'],\n",
            " 'location': [' Oslo; Helsingfors; Ballerup'],\n",
            " 'name': ['Nets Group']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=29> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=28> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=30> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' E-Commerce, Fashion, Web Technology'],\n",
            " 'location': [' Amsterdam; Kyiv'],\n",
            " 'name': ['Neocles ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' Transportation'],\n",
            " 'location': [' Paris'],\n",
            " 'name': ['Heetch']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' B2B, Information Technology, SaaS'],\n",
            " 'location': [' Shibuya City; Nagoya; Fukuoka'],\n",
            " 'name': ['HENNGE K.K.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' Charity, Non-Profit, Publishing'],\n",
            " 'location': [' London'],\n",
            " 'name': ['Which?']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Tech opportunities in Singapore']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' Ad Tech, Advertising Technology'],\n",
            " 'location': [' Tel Aviv-Yafo; London; Singapore'],\n",
            " 'name': ['Amobee, Inc']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' SaaS, Software Development, Web Development'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['AppEvolve']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' IT Consulting, Software Consulting, Technology Consulting'],\n",
            " 'location': [' Lappeenranta; Joensuu; Tammerfors'],\n",
            " 'name': ['CGI Suomi']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' B2B, Data & Analytics, Financial Technology'],\n",
            " 'location': [' Singapore; Hong Kong Island; London'],\n",
            " 'name': ['MarketAxess Holdings Inc.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=27>\n",
            "{'company_type': [' eLearning, K-12, Online Education'],\n",
            " 'location': [' Boulder'],\n",
            " 'name': ['Outschool']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['LINE Fukuoka']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Cybersecurity, Network Security, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Mendrisio; San Francisco'],\n",
            " 'name': ['Nozomi Networks']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Bioinformatics, Computer Software, Digital Health'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Self Decode']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Banking'],\n",
            " 'location': [' Singapore; Luxembourg; Zürich'],\n",
            " 'name': ['Bank Julius Baer & Co. Ltd.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Hardware Development, Semiconductors, Software Development '\n",
            "                  '/ Engineering'],\n",
            " 'location': [' Chandler; Veldhoven; East District'],\n",
            " 'name': ['ASML']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Data & Analytics, Marketing Software, SaaS'],\n",
            " 'location': [' Helsinki; Vilnius'],\n",
            " 'name': ['Supermetrics Oy']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Internet of Things, Manufacturing, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Chicago; Peoria; Bengaluru'],\n",
            " 'name': ['Caterpillar Inc.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Enterprise Software, Information Technology'],\n",
            " 'location': [' Dublin; Sydney; San Diego'],\n",
            " 'name': ['ServiceNow']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Agile Software Development, Legal Technology, legal '\n",
            "                  'accounting software'],\n",
            " 'location': [' Sydney'],\n",
            " 'name': ['Smokeball ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=29>\n",
            "{'company_type': [' Data & Analytics, SaaS, Web Technology'],\n",
            " 'location': [\" Saint Julian's\"],\n",
            " 'name': ['Hotjar']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' Digital Health, Enterprise Software, Software Development '\n",
            "                  '/ Engineering'],\n",
            " 'location': [' Albany; Silver Spring; Pittsburgh'],\n",
            " 'name': ['3M Health Information Systems and The Digital Science Community ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' eCommerce, Information Technology'],\n",
            " 'location': [' Amsterdam'],\n",
            " 'name': ['funda']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' eCommerce, Telecommunications'],\n",
            " 'location': [' Fulda'],\n",
            " 'name': ['starmobile GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' Consulting, Software Development / Engineering'],\n",
            " 'location': [' Manchester; Edinburgh; London'],\n",
            " 'name': ['Zuhlke Engineering Ltd']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' Finance, Financial Services, Financial Technology'],\n",
            " 'location': [' Westlake; Salt Lake City; Durham'],\n",
            " 'name': ['Fidelity Investments']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' B2B, Data & Analytics, Financial Technology'],\n",
            " 'location': [' Singapore; Hong Kong Island; London'],\n",
            " 'name': ['MarketAxess Holdings Inc.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' Mobile Development, Product Development, Web Development'],\n",
            " 'location': [' Washington'],\n",
            " 'name': ['Enovational']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' Education Technology'],\n",
            " 'location': [' Wilmington'],\n",
            " 'name': ['LINQ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' Gaming'],\n",
            " 'location': [' Hamburg'],\n",
            " 'name': ['Goodgame Studios']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=31> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=28>\n",
            "{'company_type': [' eCommerce, Food & Beverage, Logistics & Distribution'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['Delivery Hero SE']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Developer APIs, Hospitality, SaaS'],\n",
            " 'location': [' Europe'],\n",
            " 'name': ['Impala']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Advertising, Information Technology, Recruiting'],\n",
            " 'location': [' London; New York'],\n",
            " 'name': ['Stack Overflow']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Financial Technology'],\n",
            " 'location': [' Cape Town; Amsterdam; Johannesburg'],\n",
            " 'name': ['Yoco']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Cybersecurity'],\n",
            " 'location': [' Toronto; Indianapolis; Belfast'],\n",
            " 'name': ['Proofpoint']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' DevOps, Information Technology, Internet Infrastructure'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['LogDNA']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Data Integration, Marketing Automation, SaaS'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['SyncSmart.io (by LyntonWeb.com)']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Banking, Financial Services, Financial Technology'],\n",
            " 'location': [' Sydney; Eveleigh'],\n",
            " 'name': ['Commonweath Bank']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Advertising, Online Education, Social Networking'],\n",
            " 'location': [' Beijing; New York; Sunnyvale'],\n",
            " 'name': ['LinkedIn']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' E-Commerce, Logistics & Distribution, Shipping'],\n",
            " 'location': [' Austin'],\n",
            " 'name': ['uShip']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=30>\n",
            "{'company_type': [' Computer Software, Enterprise Software, Software '\n",
            "                  'Consulting'],\n",
            " 'location': [' Ataşehir; Sarajevo; Irvine'],\n",
            " 'name': ['Authority Partners']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=32> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=33> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Big Data, Enterprise Software, Information Technology'],\n",
            " 'location': [' Cambridge; Pittsburgh'],\n",
            " 'name': ['Vertica']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Domains, Internet Infrastructure, Mobile'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Tucows']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Financial Technology'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['PayPay Corporation.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Marketplace, Software Development, Sports Technology'],\n",
            " 'location': [' Boston; Las Vegas; Sofia'],\n",
            " 'name': ['DraftKings']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Digital Health, Healthcare, Research Pharmacy'],\n",
            " 'location': [' Ingelheim am Rhein'],\n",
            " 'name': ['BI X GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Agile Software Development, Software Development / '\n",
            "                  'Engineering, Technology Staffing'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Andela']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Artificial Intelligence, Big Data, Machine Learning'],\n",
            " 'location': [' San Francisco; London'],\n",
            " 'name': ['Quantcast']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Digital Health, Web Technology'],\n",
            " 'location': [' Helsinki; San Mateo'],\n",
            " 'name': ['Meru Health']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Computer Software, Information Technology, Supply Chain '\n",
            "                  'Management Software'],\n",
            " 'location': [' Sydney; Singapore; Nanjing'],\n",
            " 'name': ['WiseTech Global Ltd.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=31>\n",
            "{'company_type': [' Adserver, Agile Software Development, Programmatic '\n",
            "                  'Advertising'],\n",
            " 'location': [' Freiburg im Breisgau'],\n",
            " 'name': ['Active Agent AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Big Data, Programmatic Advertising, Supply Side Platform'],\n",
            " 'location': [' Hamburg'],\n",
            " 'name': ['Yieldlab AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Big Data'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['AdClear GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Digital Health, Healthcare, SaaS'],\n",
            " 'location': [' Toronto'],\n",
            " 'name': ['OnCall Health']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Finance, Financial Services, Insurance'],\n",
            " 'location': [' Mölndal; Hvidovre; Espoo'],\n",
            " 'name': ['If P&C Insurance']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Computer Software'],\n",
            " 'location': [' Reston; Ashburn; Tampa'],\n",
            " 'name': ['Babel Street']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Energy & Utilities'],\n",
            " 'location': [' London'],\n",
            " 'name': ['So Energy']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' blockchain, Financial Technology, Gambling'],\n",
            " 'location': [' Tallinn'],\n",
            " 'name': ['The Yolo Group ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Oil & Gas'], 'location': [' London'], 'name': ['bp plc']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' eCommerce, Finance, Retail'],\n",
            " 'location': [' Helsinki'],\n",
            " 'name': ['Suomen Osuuskauppojen Keskuskunta (SOK)']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=32>\n",
            "{'company_type': [' Electronics, Software Development / Engineering'],\n",
            " 'location': [' Tettnang; Essen'],\n",
            " 'name': ['ifm electronic GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Cybersecurity'],\n",
            " 'location': [' Sydney; Northgate'],\n",
            " 'name': ['Daltrey']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Ad Tech, Data & Analytics, Marketing'],\n",
            " 'location': [' New York; Toronto; Los Angeles'],\n",
            " 'name': ['Horizon Media Holdings, Inc']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Retail, Technical Services, Web Technology'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['The Home Depot']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Data & Analytics, Databases, Information Technology'],\n",
            " 'location': [' Ho Chi Minh City; Berlin; Albania'],\n",
            " 'name': ['Y42']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Platforms, Real Estate, Virtual Reality'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['ZIEGERT Real Estate']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Agile Software Development, Content Marketing, Web '\n",
            "                  'Technology'],\n",
            " 'location': [' Newark; Cambridge; Seattle'],\n",
            " 'name': ['Audible']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' AI Research, Data & Analytics, Industrial Automation'],\n",
            " 'location': [' Ludwigshafen am Rhein; Schwarzheide; Berlin'],\n",
            " 'name': ['BASF ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Information Technology, SaaS, scaleup'],\n",
            " 'location': [' Stockholm; Toronto'],\n",
            " 'name': ['Mentimeter']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Software Development, Web Hosting, Web Technology'],\n",
            " 'location': [' Budapest'],\n",
            " 'name': ['Kinsta']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=33>\n",
            "{'company_type': [' Computer Software, eCommerce, Platforms'],\n",
            " 'location': [' Sint-Niklaas'],\n",
            " 'name': ['Vavato']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=38> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=34> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=39> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Consulting, Digital Marketing, Financial Services'],\n",
            " 'location': [' Hamburg; Berlin; Wien'],\n",
            " 'name': ['Serrala']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Cryptocurrency, Financial Services, Financial Technology'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Bitfinex']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Computer Games, Platforms, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Crazy Games']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Agile Software Development, Computer Software, Enterprise '\n",
            "                  'Software'],\n",
            " 'location': [' United States; Canada; United Kingdom'],\n",
            " 'name': ['Adaptavist']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Customer Data Platform, Data & Analytics, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' London'],\n",
            " 'name': ['Snowplow Analytics']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Agile Software Development, HR Services, Payroll'],\n",
            " 'location': [' Chicago; Ruddington; Nottingham'],\n",
            " 'name': ['MHR']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Broadcast, Digital Media, Digital Video Distribution'],\n",
            " 'location': [' Knoxville; Sterling; New York'],\n",
            " 'name': ['Discovery Direct-to-Consumer (Discovery Inc.)']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Information Services, Media'],\n",
            " 'location': [' Zürich'],\n",
            " 'name': ['ARGUS DATA INSIGHTS Schweiz AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' Automotive, Software Development / Engineering'],\n",
            " 'location': [' Brașov; Timișoara'],\n",
            " 'name': ['Elektrobit Automotive Romania (EB) ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=35> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=38>\n",
            "{'company_type': [' eCommerce, Logistics & Distribution'],\n",
            " 'location': [' Riyadh; عزبة فهمي'],\n",
            " 'name': ['Mrsool']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=40> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=41> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Consulting, Software Development / Engineering'],\n",
            " 'location': [' Singapore'],\n",
            " 'name': ['Zuhlke Engineering Singapore']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Agile Software Development, Computer Software, IT '\n",
            "                  'Consulting'],\n",
            " 'location': [' Hong Kong Island'],\n",
            " 'name': ['Zuhlke Engineering Hongkong']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Communications, Software Development'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['AVM GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Cybersecurity, Defence & Security'],\n",
            " 'location': [' Manchester; Brockworth; Leeds'],\n",
            " 'name': ['BAE Systems Digital Intelligence']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Agile Software Development, Messaging, Mobile Application'],\n",
            " 'location': [' Stuttgart'],\n",
            " 'name': ['Flip App']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Cloud Computing, Cloud Services, Cloud-Based Solutions'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Amazon Web Services (AWS)']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Continuous Delivery, DevOps, Software Development'],\n",
            " 'location': [' Brisbane City'],\n",
            " 'name': ['Octopus Deploy']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Cybersecurity, IT Security'],\n",
            " 'location': [' Bochum'],\n",
            " 'name': ['G DATA CyberDefense AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' London; Berlin; Consolação'],\n",
            " 'name': ['PPRO ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=34>\n",
            "{'company_type': [' Digital Agency'],\n",
            " 'location': [' Montréal; Québec'],\n",
            " 'name': ['nventive']}\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=37> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=36> (referer: None)\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' E-Commerce, Internet Marketing, Online Advertising'],\n",
            " 'location': [' Utrecht'],\n",
            " 'name': ['Channable']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Consulting, Digital Agency, Software Development'],\n",
            " 'location': [' Santa Monica; Seattle; New York'],\n",
            " 'name': ['TheoremOne, LLC']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Architecture, Design, Software Development / Engineering'],\n",
            " 'location': [' Berlin; Köln'],\n",
            " 'name': ['BCG Platinion']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Financial Services, Financial Technology'],\n",
            " 'location': [' San Francisco; Seattle; Denver'],\n",
            " 'name': ['Forge']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Artificial Intelligence, Machine Learning, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' London'],\n",
            " 'name': ['QuantumBlack']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Biotechnology, Pharmaceuticals'],\n",
            " 'location': [' Toulouse; Milton; Göttingen'],\n",
            " 'name': ['Evotec SE']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Banking, Financial Services, Financial Technology'],\n",
            " 'location': [' Chicago; Riverwoods'],\n",
            " 'name': ['Discover Financial Services']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' B2C, Consumer Electronics, Internet of Things'],\n",
            " 'location': [' Charlotte; São Paulo; Kraków'],\n",
            " 'name': ['Electrolux']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Agile Software Development, Financial Technology, Forex '\n",
            "                  'Trading'],\n",
            " 'location': [' Kraków; Bengaluru; London'],\n",
            " 'name': ['IG Group']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=39>\n",
            "{'company_type': [' Information Technology, Software Development, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' London; Düsseldorf'],\n",
            " 'name': ['Vodafone']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Computer Software'],\n",
            " 'location': [' Montreal'],\n",
            " 'name': ['GSoft']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Advertising Technology, Online Advertising, Programmatic '\n",
            "                  'Advertising'],\n",
            " 'location': [' London; Milano; New York'],\n",
            " 'name': ['Ogury']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Computer Software, Information Technology, SaaS'],\n",
            " 'location': [' San Francisco; Paris; Berlin'],\n",
            " 'name': ['uberall GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Big Data, Cloud-Based Solutions, Enterprise Software'],\n",
            " 'location': [' Helsinki; Atlanta; London'],\n",
            " 'name': ['RELEX']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Financial Technology, SaaS'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Pento']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Data & Analytics, Financial Technology, Logistics and '\n",
            "                  'Supply Chain'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Leaf Logistics']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Digital Video Distribution, Ticketing, Video Streaming'],\n",
            " 'location': [' Minato City'],\n",
            " 'name': ['ZAIKO K.K.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Architecture, Computer Software, IT Consulting'],\n",
            " 'location': [' Mechelen; Leuven; Gent'],\n",
            " 'name': ['AE nv/sa']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Artificial Intelligence, Information Technology, '\n",
            "                  'Telecommunications'],\n",
            " 'location': [' Helsingfors; Oulu; Kuopio'],\n",
            " 'name': ['Elisa Polystar']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=35>\n",
            "{'company_type': [' Enterprise Web Solutions, Information Technology, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Wien; Klagenfurt am Wörthersee; Gdańsk'],\n",
            " 'name': ['Dynatrace']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' IT Consulting'],\n",
            " 'location': [' Wrocław; Gdańsk; Torino'],\n",
            " 'name': ['Luxoft ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Databases, DBaaS, Software Development / Engineering'],\n",
            " 'location': [' Durham'],\n",
            " 'name': ['Percona Staffing LLC']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' Barcelona; Paris'],\n",
            " 'name': ['Adevinta']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Health & Fitness'],\n",
            " 'location': [' San Francisco'],\n",
            " 'name': ['AllTrails']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' E-Commerce, Retail'],\n",
            " 'location': [' Mannheim'],\n",
            " 'name': ['BAUHAUS AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Big Data, Cloud-Based Solutions, High-Performance '\n",
            "                  'Computing'],\n",
            " 'location': [' West Perth; Houston; London'],\n",
            " 'name': ['DUG Technology']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Education Technology, SaaS'],\n",
            " 'location': [' Mountain View; Austin; Denver'],\n",
            " 'name': ['Udemy']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' Seattle; München; London'],\n",
            " 'name': ['Highspot']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' Data Science, IT Security, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Bern; Schlieren'],\n",
            " 'name': ['Zühlke Engineering AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=40>\n",
            "{'company_type': [' E-Commerce, Information Technology, Retail'],\n",
            " 'location': [' Utrecht'],\n",
            " 'name': ['Bol.com']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Food & Beverage, Retail'],\n",
            " 'location': [' Altoona; Claysburg; Gahanna'],\n",
            " 'name': ['Sheetz']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Internet of Things, Software Development / Engineering, '\n",
            "                  'Telematics'],\n",
            " 'location': [' No office location'],\n",
            " 'name': ['Geotab']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Biotechnology, Pharmaceuticals, Science'],\n",
            " 'location': [' Hyderabad; Budapest; Austin'],\n",
            " 'name': ['Thermo Fisher Scientific Careers']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Artificial Intelligence, Autonomous Driving, Defense'],\n",
            " 'location': [' Warner Robins; San Antonio; Boulder'],\n",
            " 'name': ['Southwest Research Institute']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Agile Software Development, Cloud Services, Product '\n",
            "                  'Development'],\n",
            " 'location': [' Cluj-Napoca; Santa Ana; Reston'],\n",
            " 'name': ['Modus Create']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Cloud Computing, Information Technology, Internet of '\n",
            "                  'Things'],\n",
            " 'location': [' Taipei City; London; Montreal'],\n",
            " 'name': ['Canonical']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Data & Analytics, Software Development, Test Automation'],\n",
            " 'location': [' Veghel'],\n",
            " 'name': ['Jumbo Supermarkets']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=41>\n",
            "{'company_type': [' Computer Software, eCommerce, Health Care'],\n",
            " 'location': [' Ottawa; Scottsdale'],\n",
            " 'name': ['Fullscript']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Digital Media, Product Development, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Darmstadt; Tullamarine; Newbury'],\n",
            " 'name': ['Bolinda Labs GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Automotive, Mobility Services, ridesharing'],\n",
            " 'location': [' Berlin; Hamburg'],\n",
            " 'name': ['MOIA GmbH']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' CRM, SaaS, Vehicle Tracking'],\n",
            " 'location': [' Leeds'],\n",
            " 'name': ['BigChange Ltd']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Agile Software Development, Automotive'],\n",
            " 'location': [' Berlin'],\n",
            " 'name': ['MBition (Mercedes Benz AG)']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Agile Software Development, B2B, Web Technology'],\n",
            " 'location': [' San Francisco; Nové Mesto; London'],\n",
            " 'name': ['Slido']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Information Technology'],\n",
            " 'location': [' Sofia; Cologne; Prague'],\n",
            " 'name': ['DHL Freight Enterprise Software Solutions']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' eCommerce, Internet Marketing, Retail'],\n",
            " 'location': [' San Francisco; Los Angeles; New York'],\n",
            " 'name': ['The RealReal']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Cloud-Based Solutions, IT Security, Software Development / '\n",
            "                  'Engineering'],\n",
            " 'location': [' Singapore; Zürich; Bern'],\n",
            " 'name': ['ti&m AG']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' Retail'],\n",
            " 'location': [' No office location'],\n",
            " 'name': [\"DICK'S Sporting Goods, Inc. \"]}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=37>\n",
            "{'company_type': [' E-health, Mobile Application, Software Development'],\n",
            " 'location': [' Delft'],\n",
            " 'name': ['Innovattic']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Digital Marketing, Marketing Automation, Real Estate'],\n",
            " 'location': [' Oslo'],\n",
            " 'name': ['Marketer Technologies AS']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' B2C, eCommerce, Retail'],\n",
            " 'location': [' Stephanskirchen'],\n",
            " 'name': [\"MARC O'POLO International GmbH\"]}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Computer Software, Healthcare'],\n",
            " 'location': [' Tampa'],\n",
            " 'name': ['Nextech Systems, LLC']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Hardware Development, Machine Learning, Software '\n",
            "                  'Development / Engineering'],\n",
            " 'location': [' Budapest; Greensboro; Kista'],\n",
            " 'name': ['Qamcom ']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Consulting, Design, Software Development'],\n",
            " 'location': [' Lisboa; 渋谷区; Amsterdam'],\n",
            " 'name': ['Reaktor']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Application Security Testing, Cybersecurity, Security '\n",
            "                  'Software'],\n",
            " 'location': [\" Giv'atayim; Atlanta; Braga\"],\n",
            " 'name': ['Checkmarx']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' eCommerce, Printing, Web Technology'],\n",
            " 'location': [' Watford; Schaumburg'],\n",
            " 'name': ['Mixam']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Recruiting, Software Development'],\n",
            " 'location': [' New York; San Francisco'],\n",
            " 'name': ['Greenhouse Software, Inc.']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Financial Technology'],\n",
            " 'location': [' Auckland; London'],\n",
            " 'name': ['LMAX Group']}\n",
            "2022-04-10 01:34:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://stackoverflow.com/jobs/companies?pg=36>\n",
            "{'company_type': [' Information Technology, Product Development, Real Estate'],\n",
            " 'location': [' Sydney; Melbourne'],\n",
            " 'name': ['Ailo']}\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=47> (referer: None)\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=42> (referer: None)\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=43> (referer: None)\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=44> (referer: None)\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=45> (referer: None)\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://stackoverflow.com/jobs/companies?pg=46> (referer: None)\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "2022-04-10 01:34:18 [scrapy.extensions.feedexport] INFO: Stored csv feed (408 items) in: Question6_all_pages_data.csv\n",
            "2022-04-10 01:34:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 13977,\n",
            " 'downloader/request_count': 47,\n",
            " 'downloader/request_method_count/GET': 47,\n",
            " 'downloader/response_bytes': 1053776,\n",
            " 'downloader/response_count': 47,\n",
            " 'downloader/response_status_count/200': 47,\n",
            " 'elapsed_time_seconds': 3.33643,\n",
            " 'feedexport/success_count/FileFeedStorage': 1,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2022, 4, 10, 1, 34, 18, 378971),\n",
            " 'httpcompression/response_bytes': 4392293,\n",
            " 'httpcompression/response_count': 47,\n",
            " 'item_scraped_count': 408,\n",
            " 'log_count/DEBUG': 464,\n",
            " 'log_count/INFO': 11,\n",
            " 'memusage/max': 94613504,\n",
            " 'memusage/startup': 94613504,\n",
            " 'response_received_count': 47,\n",
            " 'scheduler/dequeued': 47,\n",
            " 'scheduler/dequeued/memory': 47,\n",
            " 'scheduler/enqueued': 47,\n",
            " 'scheduler/enqueued/memory': 47,\n",
            " 'start_time': datetime.datetime(2022, 4, 10, 1, 34, 15, 42541)}\n",
            "2022-04-10 01:34:18 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        }
      ],
      "source": [
        "!scrapy runspider question6.py -o Question6_all_pages_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ8a6K7LHsZO"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "WebScraping6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}